{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1adc59a4",
   "metadata": {},
   "source": [
    "### Импортируем нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff05ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отключаем графический ускоритель\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "# Импортируем требуемые библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lib.graph import *\n",
    "from lib.myutil import *\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ed3df",
   "metadata": {},
   "source": [
    "#### Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47531414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LastPriceKF</th>\n",
       "      <th>dTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-02 12:25:46</th>\n",
       "      <td>80.344995</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-02 12:25:49</th>\n",
       "      <td>80.342481</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-02 12:25:52</th>\n",
       "      <td>80.342486</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-02 12:25:55</th>\n",
       "      <td>80.338911</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-02 12:25:58</th>\n",
       "      <td>80.337806</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     LastPriceKF  dTime\n",
       "DateTime                               \n",
       "2020-11-02 12:25:46    80.344995    4.0\n",
       "2020-11-02 12:25:49    80.342481    3.0\n",
       "2020-11-02 12:25:52    80.342486    3.0\n",
       "2020-11-02 12:25:55    80.338911    3.0\n",
       "2020-11-02 12:25:58    80.337806    3.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = '~/notebook_server/data/USDRUB.csv'\n",
    "usdrub = pd.read_csv(csv_path)\n",
    "features_considered = ['LastPriceKF', 'dTime']\n",
    "uni_data = usdrub[features_considered]\n",
    "uni_data.index = usdrub['DateTime']\n",
    "uni_data = uni_data.iloc[1:] # исключаем первую(нулевую выборку)\n",
    "uni_data.head()\n",
    "#uni_data['LastPriceKF'].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6208557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделяем данные\n",
    "uni_data = uni_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d539bf4",
   "metadata": {},
   "source": [
    "#### Подготавливаем данные для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94ac92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Устанавливаем параметры генерации данных\n",
    "dataset_norm = dataset_normalization(uni_data)\n",
    "#plt.hist(dataset_norm[:,0], facecolor='blue', alpha=0.5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5776b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_past_history = 200\n",
    "univariate_future_target = 1\n",
    "\n",
    "# Генерируем данные для нейросети\n",
    "uni_data_all = reform_data(dataset=dataset_norm, \n",
    "                            history_size=univariate_past_history,\n",
    "                            target_size=univariate_future_target,\n",
    "                            shuffle=False)\n",
    "\n",
    "Nsamples = len(uni_data_all)\n",
    "print(f'количество выборок: {Nsamples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e3743",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = 0.80\n",
    "TRAIN_SPLIT = int(Nsamples * TRAIN_SPLIT)\n",
    "\n",
    "x_uni, y_uni = preparate_data(dataset=uni_data_all, \n",
    "                                history_size=univariate_past_history,\n",
    "                                target_size=univariate_future_target)\n",
    "\n",
    "x_train_uni = x_uni[:TRAIN_SPLIT]\n",
    "y_train_uni = y_uni[:TRAIN_SPLIT]\n",
    "\n",
    "x_val_uni = x_uni[TRAIN_SPLIT:]\n",
    "y_val_uni = y_uni[TRAIN_SPLIT:]\n",
    "#x_train_uni, x_val_uni, y_train_uni, y_val_uni = train_test_split(x_uni, y_uni, test_size=(1-TRAIN_SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c924588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand_values = random.randint(0, x_train_uni.shape[0])\n",
    "#show_plot([x_train_uni[0], y_train_uni[0]], 0, 'Sample Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "#print(x_train_uni.shape[0])\n",
    "BUFFER_SIZE = 1024\n",
    "\n",
    "train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
    "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
    "val_univariate = val_univariate.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548ba7d",
   "metadata": {},
   "source": [
    "#### Формируем структуру нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(50, input_shape=x_train_uni.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "simple_lstm_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b903f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x, y in val_univariate.take(1):\n",
    "#    print(simple_lstm_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train_uni.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46c9cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "VER = '1_0_0'\n",
    "EPOCHS = 3\n",
    "simple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n",
    "                    steps_per_epoch=int(x_train_uni.shape[0]//BATCH_SIZE),\n",
    "                    validation_data=val_univariate, validation_steps=int(x_val_uni.shape[0]//BATCH_SIZE))\n",
    "\n",
    "simple_lstm_model.save(f'~/notebook_server/result/{VER}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d67007",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_univariate.take(10):\n",
    "    #rand_values = random.randint(0, x_train_uni.shape[0])\n",
    "    plot = show_plot([x[0].numpy(), y[0].numpy(),\n",
    "                    simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56533eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_init = True\n",
    "\n",
    "# Количество точек предсказания\n",
    "num_point_prediction = 40\n",
    "# Нулевые массивы для заполнения данные\n",
    "predictable_sample = np.zeros((BATCH_SIZE, 200, 1))\n",
    "history_data = np.array([])\n",
    "true_future = np.array([]) \n",
    "predicted_future = np.array([])\n",
    "pre_window = np.array([])\n",
    "\n",
    "offset = 4\n",
    "\n",
    "for x, y in val_univariate.take(19):\n",
    "    history_value = x\n",
    "    true = y\n",
    "\n",
    "#print(f'history_value: {history_value}')\n",
    "history_sample = history_value[offset].numpy()\n",
    "pre_window = np.append(pre_window, history_sample)\n",
    "#print(f'history[0].numpy(): {history[0].numpy()}')\n",
    "#print(f'predict_window: {pre_window}')\n",
    "\n",
    "for num in range(num_point_prediction):\n",
    "    # Из массива формируем выборку для предсказания\n",
    "    true_future = np.append(true_future, true[num+offset])\n",
    "    \n",
    "    if first_init:\n",
    "        predictable_sample[0] = history_sample #history_value[num+offset].numpy()\n",
    "        first_init = False\n",
    "        #print(f'{num}. Historical data')\n",
    "    else:\n",
    "        predictable_sample[0] = pre_window\n",
    "        #print(f'{num}. Calculated data')\n",
    "    \n",
    "    # Вычисляем предсказание\n",
    "    predicted_sample = simple_lstm_model.predict(predictable_sample)[0]\n",
    "    predicted_future = np.append(predicted_future, predicted_sample)\n",
    "\n",
    "    # Добавляем в конец списка предсказанный элемент\n",
    "    pre_window = np.append(pre_window, predicted_sample)\n",
    "    # Удаляем первый элемент (сохраянем размернойсть массива)\n",
    "    pre_window = np.delete(pre_window, 0)\n",
    "    pre_window = np.reshape(pre_window, (pre_window.shape[0], 1))\n",
    "\n",
    "#print(f'true_future: {true_future}')\n",
    "#print(f'predicted_future: {predicted_future}')\n",
    "multi_step_plot(history_sample, true_future, predicted_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7793b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
